---
title: Module 3 Lecture 21 - Radar interferometry
teaching: 
exercises: 
questions:
- "???"
objectives:
- "= = ="
keypoints:
- "- - -"
---

### Module 3 Lecture 21: Radar interferometry

We now start a treatment of some innovative uses of radar imaging that are not available to us in the same form with optical imagery. But first, we summarize the benefits of radar imagery. As we have seen in this series of lectures on radar, remote sensing, imaging with radar brings a number of advantages, including that imaging can be carried out through Cloud cover, imaging can be carried out at any time of day or night, sea state features can be detected and mapped. Imaging is sensitive to soil moisture. For very dry surfaces and long wavelengths, subsurface imaging is possible. Floods can be detected beneath forest canopies. At long wavelengths, forests back scatter is dominated by trunks, allowing woody biomass to be assessed. At shorter wavelengths, green leaf biomass can be assessed. Finally, radar scattering mechanisms at different from but complimentary to those experienced with optical imagery, suggesting there are benefits in using the two imaging modalities together. Now, let's look at a very different style of operation. Because radar uses pure or coherent radiation for imaging, as against the incoherent sunlight used in optical imagery, we can interfere two radar signals intentionally, to achieve a remarkable new application called radar interferometry. It allows topographic mapping to be carried out and changes in topography with time to be detected. We have seen interference in radar before, as in the speckle created by the interfering backscattered electric field vectors from incremental scatterers within the pixel and of course, in inbred resonance. The relative phase angles of the fields cause the interference. Those phenomena though are natural scattering mechanisms that depend on phase difference. What we want to do now, is use the difference in phase between two radar signals deliberately. We will see that that will allow us to determine the height of a pixel, as well as its latitude and longitude, and how that height changes with time. The technique is commonly known as interferometric SAR or InSAR. Consider two radars operating side-by-side at the same altitude, irradiating a region on the ground at height, h above a datum. The horizontal distance between the radars, B is called the baseline. Because the two radars are at different slant distances to the target shown as R_1 and R_2, there will be a difference in their phases on reception back at the radars for a pulse that has transmitted from both radars simultaneously. That two-way phase difference can be shown to be given by the first expression on this slide. If we differentiate that phase difference formula with respect to the height of that region being irradiated, we get an expression for phase sensitivity, which is a function of the known system parameters. As an example, look at the interfering of two S_1 beams. Substituting the relevant numbers into the formula shows us that we get almost 10 degrees of phase difference between the beams for every one meter change in elevation. We can invert and integrate the last equation to get height as a function of the differential phase angle, in which alpha subscript IF is called the interferometric phase factor. The constant of integration can be found from the height and phase difference at a particular location if that is important. Thus, by finding the phase difference at each pixel position, we can determine the corresponding pixel height, allowing a topographic map to be determined. For completeness, we note that we can represent the two separate radar signals at position i j in terms of fields, as shown in the center of this slide. When they are received, the complex product is formed as shown. The angle at which is the interferometric phase difference. This type of signal is actually called the interferogram. There are, however, some practical difficulties with using phase. In a previous slide, we saw that the phase difference between the received signals is given by the formula shown in the first line of the slide. It shows that the phase difference varies because of a change in incidents angle. There are two mechanisms that affect incidence angle. The first is height variations, which is what we are interested in and the other is position across the swath, which occurs even for a flat earth, and effectively interferes with the height-dependent changes in incidence angle which we are trying to find. This is called the flat earth variation of phase difference. It needs to be removed from the recorded phase difference between the two radars, which is reasonably straightforward to do. The correction is sometimes called phase flattening. The second problem with phase, which needs to be compensated concerns its cyclic nature. That can be seen in the example on this slide, which illustrates how there is an ambiguity in interpreting the difference in phase between two sinusoids. Phase angle is modulo 2 pi, so even though the absolute phase might surpass 2 pi in practice, mathematically, it gets reset to the range between zero and two pi. Again, the effect can be compensated fairly easily before the image product that is the interferogram is produced. This process is called phase unwrapping. By phase flattening, and phase unwrapping as standard operations carried out when generating topographic information right to out imagery. Interestingly, if we have two radars irradiating the surface, there can be two styles of operation. The option exists for having both transmit and receive, or only one transmit and both receive. The latter style of operation, called the standard mode, is common when both radars are carried on the same platform. When two separate platforms that used or a single platform is used on successive orbits with a baseline between them that is called repaid pass interferometry, then the formal style of operation issues and it is called the ping pong mode. Having summarized the main spur which topographic detail can be mapped with radar interferometry, we present in this slide an example produced by the TanDEM-X topographic satellite mapping mission. This was acquired using two satellites operating in a standard interferometric mode, one transmitting and both receiving. This map of matter is a very good examples of the detail that can be obtained. Summarizing this lecture: Because SAR uses coherent radiation, which preserves the phase angle of the transmitted and received electric fields, it is possible to employ two radars side-by-side to detect terrain height. As a result, three-dimensional topographic maps can be created. Usually, for SAR, they are called interferograms. Phase variations associated with a change of incidence angle as though the earth was flat have to be removed when creating the interferogram. That is called phase flattening. The 2 pi ambiguity and phase must also be compensated for. That is called phase unwrapping. There are two styles of operation, the standard and the ping pong mode. The two radars can be on the same platform or onto platforms flying side-by-side. Alternatively, a single radar and platform can be used, but with images tagged on subsequent orbits, which are then interfered to form the interferogram that assumes that the landscape does not change during the repeat passes. These questions relate to three different aspects of SAR interferometry, all of which are important to the system designer, but probably less so to the use of the interferometric product, which would normally be calibrated in terms of height. 


> ## Quiz
>
> 1. ?
>
> > ## Solution
> >
> > 1. 
>    {: .solution}
 {: .challenge}

{% include links.md %}
