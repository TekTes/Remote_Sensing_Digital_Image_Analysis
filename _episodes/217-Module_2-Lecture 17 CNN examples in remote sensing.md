---
title: Module 2 Lecture 17 - CNN examples in remote sensing
teaching: 
exercises: 
questions:
- "???"
objectives:
- "= = ="
keypoints:
- "- - -"
---
### Module 2 Lecture 17: CNN examples in remote sensing

We now present two examples that illustrate much of what we have discussed in these lectures and which help us to introduce some additional concepts. These examples illustrate how convolutional neural networks have been used to handle hyperspectral data based on Spatial properties alone and a combination or spectral and spatial properties. Our first example is taken from the paper indicated. It presents examples of hyperspectral classification using several data sets based on just the spectral properties of a pixel. Here we look at a classification of the Indian pines data set, which we saw before with the support vector classifier example. The data was recorded by the average hyperspectral sensor over a region in Indiana, USA. It consists of 220 spectral channels in the range of 0.4 to 2.45 micrometers. In treating this image, the authors chose to remove some difficult classes. They retained the class as shown in the table, which also indicates the numbers of training and testing pixels used. The authors chose to use a single layer convolutional neural network as a feature selector product classification by a fully connected neural network. They applied 20 Spectral Filters in parallel and used a fully connected network with a hidden layer of 100 nodes. Note how large their filters are. Altogether, there are 81,408 unknowns to be found from the training data. From the previous slide, there were 1600 trillion pixels at 220 channels per band. That gives 352 thousand training samples, which is sufficient. This slide shows the results in the form of a thematic map and also shows the accuracy achieved compared with that generated with a support vector classifier. The accompanying ground truth map, that is the map of correct labels, allows one to assess how good the final thematic map is. Of note though, is the speckled appearance of some classes indicating that the convolutional neural network misclassified and number of pixels. Hadn't incorporated spatial filtering to, we would expect to see a much cleaner thematic map. The second example we will consider uses a two channel convolutional neural network to account for both spectral and spatial properties of hyperspectral scenes. One channel is diverted to spectral properties alone and functions very much as in the previous example. The other channel handles the spatial analysis. Both channels develop feature subsets that are then concatenated and analyzed by a fully connected neural network. The example is taken from the paper indicated in the slide. We are going to concentrate on this Salinas, California image exercise. The image segment consists of 512 by 279 pixels with 3.7 meter spatial resolution. It has 224 recorded bands, but the authors reduced those to 200 by removing channels with poor quality. The ground truth image shows that there are 16 classes with the numbers of pixels indicated. The authors chose to train the network using different percentages of ground truth pixels. We show the results here for the training data being 25 percent of the total labeled ground truth pixels. They used all the available ground truth pixels to test the generalization of the network, that is the classification performance. Here we see the convolutional neural network topology or architecture used by the authors. It consists of a spectral path at the top and the spatial path or channel at the bottom. Notice that the spatial path has 30 filters of size three by three and the spectral Path has 20 filters of size 20 by one. Each pathway has one convolutional layer and one pooling layer. The input to the spatial path consists of a spatial neighborhood about the pixel currently under consideration during training or in classification. The outputs from the two paths are flattened, concatenated and they'd fade into a fully connected neural network with two hidden layers, each with 400 nodes thus the two path convolutional neural network is acting as a feature selector for the fully connected neural network. Note that the upper layer has 16 nodes representing the 16 classes in the Salinas image. The outputs are in the form of class conditional probabilities computed with the soft max function. There are two important aspects of this example which needs to be emphasized. The spatial layer is required to capture the neighborhood or spatial properties of the pixel. The neighborhood patch of 21 by 21 pixels centered on the pixel of interest is used. The neighborhood patches created by averaging over all the spectral channels in that neighborhood. The authors also used transfer learning. That is a technique based on the concept that networks previously trained on different images but with the same sensor will most likely perform acceptably on the image of interest. This is based on the assumption that the spatial properties are similar from image to image. The authors trained the convolutional neural network layers on a different average image and then use the weights so found to initialize the convolutional neural network weights for trading on the Salinas, saying. This is not necessary in general but is a common approach based on the concept that we, as humans adapt our learning from past experience. The results shown here indicate the benefit of both spectral and spatial context, achieving an overall accuracy of 98.3 percent which is indeed very good. It is important to note that the authors runs extensive trials to find the best topology for the network. That is the numbers of convolution layers and numbers of filters, the numbers of nodes in the hidden layers and so on. Which indicates that the preparatory stages in using a convolutional neural network can be quite extensive. The idea of using neighborhood patches seems first to have been introduced by a contests in the paper referenced in this slide. Those authors used far by far patches that maintain the full spectral dimension for the patches so that spectral information, as well as spatial neighborhood of a pixel was carried by the patch. However, in order to constrain the overall data volume of the input, the authors carried out a dimensionality reduction first using a principal components transformation. This slide gives information on where convolutional neural network software can be found. Two important points are emphasized in the summary. First, patches or neighborhoods can be fed into a convolutional neural network to carry spatial context into classification. Secondly, transfer learning can be an effective and efficient way to initialize our convolutional neural network and even a fully connected neural network. These questions ask you to think carefully about some of the quantitative aspects of using a convolutional neural network. 

> ## Quiz
>
> 1. ?
>
> > ## Solution
> >
> > 1. {: .solution}
> >    {: .challenge}

{% include links.md %}