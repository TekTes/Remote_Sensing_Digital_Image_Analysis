---
title: Module 1 Lecture 20 - Applications of the principal components transform
teaching: 
exercises: 
questions:

- "???"
  objectives:
- "= = ="
  keypoints:
- "- - -"
---

### Module 1 Lecture 20 Applications of the principal components transform

We now want to examine the number of applications of principal components analysis to see how it is used in practice. There are essentially four areas in remote sensing image processing where the principal components transform finds application. The first is to produce color imagery that is easier to interpret manually, particularly when special features are important. The second is to compress imagery in terms of data volume to benefit efficient transmission and storage. The third is as an aid in classification, in which we try to reduce the number of features that define the data vectors that have to be labeled. The fourth is in detecting changes between two images of the same region taken at different times. We will now look at each of those in turn. Often in manual image interpretation, that is, photointerpretation, we use the displayed colors and our knowledge of spectral reflectance curves to identify various regions on the Earth's surface, giving them labels corresponding to the cover types of interests. However, in some applications, the colors themselves are not so important as such, but rather they can be an aid to seeing special structure in an image. That is particularly the case in exploration geology, where the delineation of surficial lithological units is important as is the identification of linear features, that is, lineaments. The vivid colors produced in principle components imagery, especially for highly correlated images, often allow structure to be seen that is otherwise very difficult to discern. We will now show an example from geology. As is often the case, geologically, significant features occur in barren regions for which the bands recorded by remote sensing instrumentation tend to be fairly similar and thus highly correlated, especially in the visible and near infrared regions of the spectrum. It is exactly this type of image that benefits from an application of principal components analysis. The images down the left-hand side of this slide are the four Landsat multi-spectral scanner bands of a region called Andamooka near Central Australia. The standard color composite formed by displaying the second near infrared band as red, the red band as green, and the green band as blue is shown on the upper right-hand side of the slide. The second column of images on the left are the four principal components generated from the original bands. The color composite formed from the principal components shown on the bottom right-hand side of the slide allows features and regions to be seen that can't be discerned easily on the original color composite and in sites of particular value in region delineation in geology. The next slide shows an example with a similar intent, although this time in a region in Australia's northern territory. The top row of images are the six reflected bands of a Landsat thematic mapper image segment recorded in the north of Australia. The thermal band has been left out. Shown also is the color composite formed from the standard mapping of near infrared to red, red to green, and green to blue. In the middle strip are the six principle components of the TM image segment. Two different PC color renditions are shown by choosing different sets of PCs with which to create the color products. Look for features that are easier to see in the PC color composites than in the standard color composite formed from the original bands. For example, note the good differentiation of water features in the second principal component example. Note also the discretization noise in the later principal components. That occurs because of simple variance, that is, the actual variance of the real information left over in the principal component. That variance is so small that the actual radiometric resolution of the sensor is showing up as the limiting factor. Now consider the use of principal components with data compression. Because the lower principle components of an image often contain little variance, and by implication, little information, they can often be discarded without sacrificing much useful information on the average. Each PC that is discarded saves that much data volume for transmission or storage. If the original image is to be reconstructed from the remaining PCs, the inverse of the transformation matrix is used with the discarded PCs replaced by matrices of zeros. When we come to look at methodologies for use in classification algorithms to produce thematic maps, we will often try to limit the number of bands or features used in the process. There are, as we will see, a number of good reasons for doing that, including the speed of the process. The original number of bands as recorded, defines the features to be used in classification. In our classification methodologies, we will look to reducing that number. There are actually many ways of reducing the number of features in a classification exercise. The use of PCs is one of the simplest, which we will now consider in outline. Remember, there are as many PCs as there are original bands. If we transform the data, we can remove the least important PCs and thus have reduced data dimensionality to handle. In other words, the original feature vectors, which have as many elements as there are bands recorded, are replaced by vectors of PC brightness values, but with only as many elements as the number of PCs retained. In some cases, that can be a very large reduction in the dimensionality of the feature vectors, giving a major improvement in the efficiency of the classification process. We will demonstrate this technique later in the course. We now come to a very interesting application of principle of components which had its origins in a 1979 conference paper and has been rediscovered many times since. It relates to the use of principal components to detect features which have changed from image to image in a multi-temporal data-set. We will develop this application of principle components by considering a model flooding example. Following which we will look at a real case involving bush fires. Both examples involve two images of the same region of the air which means the images have to be registered beforehand. We will be processing a before and an after image together, and thus we'll be dealing with twice the number of bands as with a single image. While that will happen in our life, a real example, we will work our analysis through here by just looking at a near-infrared band from before the event of interest and the corresponding bands from the image taken after the event of interest. As will become clear, it is important if the technique is to work well, that the number of pixels in the image which change as a result of the event of interest, not make up more than about 10-20 percent of the same. All other pixels remain the same from image to image. Apart from natural variations and possible seasonal differences which give rise to changes in the level of solar irradiation. This two-dimensional multi-temporal spectral space allows us to see what happens with a dynamic event such as a flood. We have plotted the near infrared brightness value of the image pixels in a space with the IR response in the first type plotted horizontally, and that for the second they've plotted vertically. Pixels which do not change from image to image except for natural variations scatter about a diagonal in the spectral domain in a roughly ellipsoidal fashion. The angle which sets scatter marks to the axis will be determined by the relative solar irradiation levels. If there are no seasonal differences, it will be close to 45 degrees in this two-dimensional space. Any pixels that were originally vegetation or soil but have become flooded in the second day will appear as a group in the regional space defined by high IR response in type one, and low IR response in type two. We now envisage where the axis of the multi-day principle components transform will appear in the space. Recall that the first PC will be in the direction of maximum data variance, and the second will be at right right that is orthogonal to it, and in the direction of the second most data variance and so on in general. Also, the PCs are essentially just a rotation of the original axis in the anti or counterclockwise direction. These axes are shown in red dashed form in this slide overlaid on the original data-set. In the second PC, we see that the flooded pixels are readily separated from those which don't change substantially from day-to-day. This is emphasized on the next slide shown separately for convenience. We now see why it is important that the change pixels not occupy too much of the scene. We want the first axis to be set by the pixels that are essentially constant. Here we see, explicitly, that in the second principal component, the static cover types occupy a different range of values of PC2 than the range occupied by those cover types which change between images. Thus, they are easily separated and will appear with very different brightness values when displayed. Here the photo pixels would appear to be dark by comparison to those which are relatively constant between those. Note that negative PC brightness values can be generated. That is not a problem, theoretically. But for display, all brightness values need to be positive. That can be handled by adding a constant to all the second PC values to make them all positive, but that does not change the results. Having established the basis of the technique that the second and like the PCs of a multitemporal dataset will show up isolated regions of change, we can now look at the real bush fire example. This employs the same pair of images that we used in the image-to-image registration example of Lecture 11. What is appealing about this case is that there are fire events in both directions. The fire scar from 1979 is regenerating in the 1980 image, while two new fire scars appeared in 1980 that were not there in 1979. As for the third example, this slide shows where the 2PC axis would appear in the multi-diadspectral domain. Again, highlighting that the major changes show up in a second PC, at least in this two-dimensional illustration. This slide reminds us that the exercise involves land set MSS data, for which there are four bands in each date. We are dealing with an eight-dimensional multitemporal image, and from which we compute eight principal components. When we look at the results in detail, we will say that the first PC looks like a weighted sum of all the eight original bands and is thus often referred to, not quite correctly, as a total brightness image. Here are the eigenvalues and eigenvectors, by row, of the eight-dimensional multi-temporal image. Note the rapid drop off in the sizes of the eigenvalues, and note that all the elements of the first eigenvector are positive. That's why the first PC is a weighted sum of the original set of bands. All other eigenvectors have some negative elements, which is why they are good at highlighting changes that have occurred between the dates. Here we see the first four principal components from the 1979-1980 image pair. We cannot see the change events in the first PC, but they are very obvious in PC2, PC3, and PC4. We will see those changes more vividly if we form a color image from those three PCs as in the next slide. Look carefully at the first principal component. It seems to have suppressed the fire events and looks like a very good image with clear topography. Here we share the color composite PC image created with the mapping Schalin, that is PC2 to red, PC3 to green, and PC4 to Blue. Note that the 1979 fire scar, which is re-vegetating in 1980, shows up as a red to magenta color. The two new fire scars show as lime green, and two stream beds on the southeast part of the image shows deep blue which in this case represents complete re-vegetation from the 1979 fire. This example has served to highlight the usefulness of the principal components transformation for highlighting differences from image to image. You should be able to find many other examples in the literature. Examine the first PCs in the examples of this lecture and see how as total brightness images, the holler topography, whereas topographic detail is missing in many of the PC images. The questions in this quiz asked you to think about computing the covariance matrix of a subset of an image. That allows much greater flexibility in using PCs, especially in applications like change detection, and in some cases, for feature reduction prior to classification. 

> ## Quiz
>
> 1. ?
>
> > ## Solution
> >
> > 1. 
> {: .solution}
{: .challenge}

{% include links.md %}